{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter file name or pathname, including \".csv\": /Users/Kelsey/Desktop/GeorgiaContinued/ACS_EDU/ACS_17_5YR_S1501_with_ann.csv\n",
      "Pathname entered: /Users/Kelsey/Desktop/GeorgiaContinued/ACS_EDU/ACS_17_5YR_S1501_with_ann.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:535: DtypeWarning: Columns (1,3,4,7,8,11,12,15,16,19,20,23,24,27,28,31,32,35,36,39,40,43,44,47,48,51,52,55,56,59,60,63,64,67,68,71,72,75,76,79,80,83,84,87,88,91,92,95,96,99,100,103,104,107,108,111,112,115,116,119,120,123,124,127,128,131,132,135,136,139,140,143,144,147,148,151,152,155,156,183,184,187,188,191,192,195,196,199,200,203,204,207,208,211,212,215,216,219,220,223,224,227,228,231,232,235,236,239,240,243,244,247,248,251,252,255,256,259,260,263,264,267,268,271,272,275,276,279,280,283,284,287,288,291,292,295,296,299,300,303,304,307,308,311,312,315,316,319,320,323,324,327,328,331,332,335,336,339,340,343,344,347,348,351,352,355,356,359,360,363,364,367,368,371,372,375,376,379,380,383,384,387,388,391,392,395,396,399,400,403,404,407,408,411,412,415,416,419,420,423,424,427,428,431,432,435,436,439,440,443,444,447,448,451,452,455,456,459,460,463,464,467,468,471,472,475,476,479,480,483,484,487,488,491,492,495,496,499,500,503,504,507,508,511,512,515,516,519,520,523,524,527,528,531,532,535,536,539,540,543,544,547,548,551,552,555,556,559,560,563,564,567,568,571,572,575,576,579,580,583,584,587,588,591,592,595,596,599,600,603,604,607,608,611,612,615,616,619,620,623,624,627,628,631,632,635,636,639,640,643,644,647,648) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3267: DtypeWarning: Columns (1,3,4,7,8,11,12,15,16,19,20,23,24,27,28,31,32,35,36,39,40,43,44,47,48,51,52,55,56,59,60,63,64,67,68,71,72,75,76,79,80,83,84,87,88,91,92,95,96,99,100,103,104,107,108,111,112,115,116,119,120,123,124,127,128,131,132,135,136,139,140,143,144,147,148,151,152,155,156,183,184,187,188,191,192,195,196,199,200,203,204,207,208,211,212,215,216,219,220,223,224,227,228,231,232,235,236,239,240,243,244,247,248,251,252,255,256,259,260,263,264,267,268,271,272,275,276,279,280,283,284,287,288,291,292,295,296,299,300,303,304,307,308,311,312,315,316,319,320,323,324,327,328,331,332,335,336,339,340,343,344,347,348,351,352,355,356,359,360,363,364,367,368,371,372,375,376,379,380,383,384,387,388,391,392,395,396,399,400,403,404,407,408,411,412,415,416,419,420,423,424,427,428,431,432,435,436,439,440,443,444,447,448,451,452,455,456,459,460,463,464,467,468,471,472,475,476,479,480,483,484,487,488,491,492,495,496,499,500,503,504,507,508,511,512,515,516,519,520,523,524,527,528,531,532,535,536,539,540,543,544,547,548,551,552,555,556,559,560,563,564,567,568,571,572,575,576,579,580,583,584,587,588,591,592,595,596,599,600,603,604,607,608,611,612,615,616,619,620,623,624,627,628,631,632,635,636,639,640,643,644,647,648) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefer different headers? Enter any character for True. Else press return.t\n",
      "Different headers is True\n",
      "which ACS dataset? enter pov, edu,  plu or gen: edu\n",
      "dataType: edu\n",
      "Processing ACS education dataset\n",
      "True\n",
      "Categories containing the following in their headers were dropped: VC08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py:2095: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_HS_25, the sum of the columns with the percent over 25 with, at minimum HS attainment, has been added \n",
      "Education does not currently have alternative headers\n",
      "Before removing null values, the length of the dataset is 1969 rows\n",
      "The 14 rows with >15 null are: [132, 166, 245, 270, 271, 389, 742, 955, 1128, 1150, 1469, 1474, 1512, 1513]\n",
      "The length of the dataset is now 1955 rows\n",
      "The remaining 0 columns with >15 null are: []\n",
      "Add county column? Enter any character for True. Else press return.t\n",
      "County column added: True\n",
      "Generate descriptive file? Enter any character for True. Else press return.t\n",
      "Generate descriptive file: True\n",
      "Enter descriptive file name or pathname, including \".csv\": t.csv\n",
      "Look in directory for the descriptive file t.csv\n",
      "Enter output file name or pathname, including \".csv\": edu.csv\n",
      "Look in directory for the output file edu.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# kgmcdaid\n",
    "\n",
    "#sebowman provided feedback and input on the method execution, code styling, user testing, specializing code for the desired audience, and more. \n",
    "\n",
    "\"\"\"\n",
    "Title: fileCleaning_userfriendly.ipynb\n",
    "Author: kgmcdaid\n",
    "\n",
    "\n",
    "This has been built using the ACS* 2017 5-year Estimates of the state of Georgia as inputs.\n",
    "It is assumed from the notes file provided with downloaded ACS data that conventions are consistent across states.\n",
    "\n",
    "\n",
    "Note: This jupyter notebook has been developed with the intention of being usable by those with minimal \n",
    "experience coding to use text inputs within the jupyter notebook to specify the route by which the files are processed. \n",
    "Aside from some individual methods, user inputs are required.\n",
    "\n",
    "\n",
    "Input:\n",
    "    inFile, an ACS csv file containing education, poverty or plumbing data. \n",
    "    If it contains a different set of ACS data, can designate as 'general,\n",
    "    and a more limited set of methods will be performed. \n",
    "    \n",
    "    Uses text inputs from user. (Optionally) may use some inputs given during the instantiation of the class. \n",
    "    User (text) input is always required for: \n",
    "        csv input/output pathname,\n",
    "        the booleans where default is False, unless instantiated as True, which are niceName, add, desc. \n",
    "\n",
    "\n",
    "\n",
    "Output: \n",
    "    A csv file containing the processed input file.\n",
    "    Optionally, a description file containing statistics for each column. \n",
    "\n",
    "TODO: \n",
    "    changeAll() TODO:\n",
    "    Convert to null: implement solutions where all but those which can be converted \n",
    "    to float are replaced with null. \n",
    "    This would be a flipped version where the replaced values are not hardcoded in. \n",
    "    Similar to what is discussed here: \n",
    "    https://stackoverflow.com/questions/1450897/remove-characters-except-digits-from-string-using-python\n",
    "\n",
    "    eduData() TODO:  \n",
    "    Make drop columns customizable. \n",
    "    In the education dataset, some columns have the entry '2,500-'.\n",
    "    This does not have an interpretation provided in the ACS notes file. \n",
    "    As such, these are marked as null.  \n",
    "    If drop=True, the columns that contain them are dropped regardless.\n",
    "\n",
    "    checkRows() TODO:\n",
    "    Could add another that triggers if checkNull > 0, where it removes the values.\n",
    "    \n",
    "    readIn()\n",
    "    Cannot be currently passed from main. \n",
    "\n",
    "    main() TODO:\n",
    "    Ability to choose between using text inputs or Argparse. \n",
    "\n",
    "Resources/references:\n",
    "    https://stackoverflow.com/questions/26347412/drop-multiple-columns-in-pandas\n",
    "    https://stackoverflow.com/questions/48158688/save-pandas-describe-for-human-readibility\n",
    "    https://github.com/pandas-dev/pandas/issues/14086\n",
    "\n",
    "    https://realpython.com/documenting-python-code/\n",
    "    https://www.python.org/dev/peps/pep-0257/\n",
    "    \n",
    "* ACS = American Community Survey, data.census.gov or factfinder.census.gov (archival)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class ACSdata():\n",
    "    \"\"\" Process the American Community Survey Data according to user inputs. \n",
    "    \n",
    "    Packages: numpy, pandas \n",
    "    \n",
    "    This processes ACS data according to its type (poverty- pov, education- edu, plumbing- plu),\n",
    "    or more generally.\n",
    "    \n",
    "    When instantiating, can call newFile() to run all methods in the class. \n",
    "    \n",
    "    Methods: \n",
    "        newFile() reads in the csv file and call all the methods that don't depend on dataType().\n",
    "        dataType() calls methods that process according to dataset type.\n",
    "        povData() removes unnecessary columns from the poverty dataset. calls changeAll, povHeaders.\n",
    "        eduData() removes unnecessary columns from the education dataset. calls changeAll, eduHeaders.\n",
    "        pluData() removes unnecessary columns from the plumbinh dataset. calls changeAll, pluHeaders.\n",
    "        \n",
    "        changeAll() processes dataframe to have only a single datatype in each column.\n",
    "        checkRows() sums null values by row, calls removeNullRows.\n",
    "        removeNullRows() removes rows with high null value counts.\n",
    "        checkCols() sums null values by column.\n",
    "        \n",
    "        readIn() checks if the file read in has a valid filename. \n",
    "        addCounty() if add is True, adds column 'County' containing county from GEO.display-label (renamed 'Geography')\n",
    "        describe() generates descriptive statistics file.\n",
    "        whatOut() specifies filename, path for output file.\n",
    "        \n",
    "        headers() changes headers for the columns with headers GEO.id2 and GEO.display-label, \n",
    "            gives option to change other headers according to dataset type.\n",
    "        povHeaders() changes some headers for pov dataset for more readable labels.\n",
    "        eduHeaders() changes some headers for edu dataset for more readable labels.\n",
    "        pluHeaders() changes some headers for plu dataset for more readable labels.\n",
    "        \n",
    "    Note: dataset type is the type of ACS data- pov, edu, plu, or a general ACS dataset. \n",
    "    The general designation performs all methods that are not specific to a dataset type. \n",
    "    \n",
    "    ACS_17_5YR_S1501, the education dataset for Georgia has inconsistent descriptions, specifically for \n",
    "    HC02_EST_VC17 -- \n",
    "    Metadata csv: Percent Estimate, Percent high school graduate or higher\n",
    "    Data with annotations csv: Population 18 to 24 years - Bachelor's degree or higher\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 data=None, \n",
    "                 niceName=False, \n",
    "                 add=False, \n",
    "                 drop=True, \n",
    "                 desc_file=None\n",
    "                ):\n",
    "        \"\"\" Initialize drop as True; initialize all other parameters as None, False or empty list.\n",
    "        \n",
    "        optional parameters:\n",
    "            inFile: None\n",
    "            df: None\n",
    "            data: None\n",
    "            niceName: bool, default False\n",
    "            drop: bool, default True\n",
    "            add: bool, default False\n",
    "            noneListR: list\n",
    "            desc: False \n",
    "        \n",
    "        \"\"\"\n",
    "        self.df = None\n",
    "        self.data = data\n",
    "        self.niceName = niceName \n",
    "        self.add = add\n",
    "        self.drop = drop\n",
    "        self.noneListR = []\n",
    "        self.noneListC = []\n",
    "        self.dropCol = []\n",
    "        self.out = None\n",
    "        \n",
    "\n",
    "    def newFile(self):\n",
    "        \"\"\" Read in the csv file and call all the methods involved in the processing of the file that are independent of the input to dataType().\n",
    "        \n",
    "        Called during instantiation. \n",
    "        Print confirmation of the output file name. \n",
    "        \"\"\"\n",
    "        self.readIn() # check if valid file\n",
    "        self.df = pd.read_csv(self.inFile)\n",
    "        self.headers()\n",
    "        self.dataType() #process according to type\n",
    "        self.checkRows()\n",
    "        self.checkCols()\n",
    "        self.addCounty()\n",
    "        self.describe()\n",
    "        self.whatOut()\n",
    "        self.df.to_csv(self.out)\n",
    "        print('Look in directory for the output file {}'.format(self.out))\n",
    "        #print('newFile done')\n",
    "       \n",
    "    def dataType(self):\n",
    "        \"\"\" Designate the type of ACS dataset. If invalid, prompt again.\n",
    "        \n",
    "        Arguments: \n",
    "            data : str - input('which ACS dataset? enter pov, edu or plu: ') or passed from main().\n",
    "\n",
    "        Valid dataset types, meanings: \n",
    "            pov = poverty dataset\n",
    "            edu = education dataset\n",
    "            plu = plumbing dataset\n",
    "            gen = a general ACS dataset\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.data == None: \n",
    "            self.data = input('which ACS dataset? enter pov, edu,  plu or gen: ')\n",
    "        print('dataType: {}'.format(self.data))\n",
    "        # if self.data == 'pov':\n",
    "        if self.data == 'pov':\n",
    "            self.n = 15\n",
    "            print('Processing ACS poverty dataset')\n",
    "            self.povData()\n",
    "        #elif self.data == 'edu':\n",
    "        elif self.data == 'edu':\n",
    "            self.n = 15\n",
    "            print('Processing ACS education dataset')\n",
    "            self.eduData()\n",
    "        # elif self.data == 'plu':\n",
    "        elif self.data == 'plu':\n",
    "            self.n = 5\n",
    "            print('Processing ACS plumbing dataset')\n",
    "            self.pluData()\n",
    "        elif self.data == 'gen' or 'general': \n",
    "            self.n = 15\n",
    "            changeAll()\n",
    "        else:\n",
    "            print('Invalid entry')\n",
    "            self.data = None\n",
    "            self.dataType()\n",
    "\n",
    "            \n",
    "    # Branching methods\n",
    "    \n",
    "    def povData(self):\n",
    "        \"\"\" Remove unnecessary columns from the poverty dataset. \n",
    "        \n",
    "        Drop the columns after column 75. Call ChangeAll. If niceName is True, call povHeaders. \n",
    "        Assumes the complete poverty table is entered.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.df = self.df.drop(self.df.iloc[:,75:None], axis=1)\n",
    "        self.changeAll()\n",
    "        if self.niceName == True:\n",
    "            self.povHeaders()\n",
    "        # print('povData done')\n",
    "        \n",
    "    def eduData(self):\n",
    "        \"\"\" Remove unnecessary columns from the education dataset.\n",
    "        \n",
    "        Drop the columns after column 184. \n",
    "        If drop == True, Drop columns containing 'VC02', 'VC08', 'HC01', 'HC03', 'HC05'\n",
    "        Call ChangeAll. If niceName is True, call eduHeaders.\n",
    "        Adds column 'min_HS_25', the summed values of columns of those over 25 with at least HS attainment. \n",
    "        Assumes the complete education table is entered.\n",
    "        \n",
    "        Arguments: \n",
    "            drop: bool. default True.\n",
    "            drop_col: list\n",
    "        \n",
    "        Note: \n",
    "        column HC02_EST_VC17 has inconsistent descriptions\n",
    "        Metadata csv: Percent Estimate, Percent high school graduate or higher\n",
    "        Data with annotations csv: Population 18 to 24 years - Bachelor's degree or higher\n",
    "        \"\"\"    \n",
    "        \n",
    "        self.df = self.df.drop(self.df.iloc[:,184:None], axis=1)\n",
    "        print(self.drop)\n",
    "        self.drop_col = ['HC01', 'HC03', 'HC05', 'VC02', 'VC08']\n",
    "        if self.drop == True:\n",
    "            for a in self.drop_col:\n",
    "                self.df = self.df.drop(self.df.columns[self.df.columns.str.contains(a)], axis=1)\n",
    "            print('Categories containing the following in their headers were dropped: {}'.format(a))\n",
    "        self.changeAll()\n",
    "        self.df['min_HS_25'] = self.df['HC02_EST_VC11'] + self.df['HC02_EST_VC12'] + self.df['HC02_EST_VC13'] \\\n",
    "                                + self.df['HC02_EST_VC14'] + self.df['HC02_EST_VC15']\n",
    "        #Percent over 25 with min HS attainment = HS diploma + Some College + Associates + Bachelors + Grad school \n",
    "        print('min_HS_25, the sum of the columns with the percent over 25 with, at minimum HS attainment, has been added ')\n",
    "        if self.niceName==True:\n",
    "            self.eduHeaders()\n",
    "        # print('eduData done')\n",
    "\n",
    "    def pluData(self):\n",
    "        \"\"\" Call changeAll, then if niceName is True, call eduHeaders. \n",
    "        \n",
    "        Intended to affect the plumbing columns of the Housing units characteristics dataset\n",
    "        Calclulate and add to dataframe: 'PLU_P_Lacking' = (Count lacking plumbing / Total)*100. \n",
    "        \"\"\"\n",
    "        \n",
    "        self.changeAll()\n",
    "        if self.niceName == True:\n",
    "            self.pluHeaders()\n",
    "            self.df['PLU_P_Lacking'] = (self.df['PLU_Lacking']/self.df['PLU_Total'])*100\n",
    "        else: \n",
    "            self.df['PLU_P_Lacking'] = (self.df['HD01_VD03']/self.df['HD01_VD01'])*100\n",
    "\n",
    "        \n",
    "    # Cleanup-related methods\n",
    "    \n",
    "    def changeAll(self):   \n",
    "        \"\"\" Process dataframe to have only a single datatype in each column.\n",
    "        \n",
    "        Remove the first row (descriptor row) and the first column (GEO.id).\n",
    "        Replace the symbols denoting excluded values with Null.\n",
    "        Convert the columns containing the collected numerical data to floats.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.df.drop(self.df.columns[0], axis=1, inplace=True) \n",
    "        self.df.drop(self.df.index[0], axis=0, inplace=True)\n",
    "        self.df.reset_index=True\n",
    "        \n",
    "        float_list = [col for col in self.df.columns]\n",
    "        float_list = float_list[2:]\n",
    "        self.df[float_list] = self.df[float_list]\\\n",
    "            .replace('-', np.nan)\\\n",
    "            .replace('**', np.nan)\\\n",
    "            .replace('***', np.nan)\\\n",
    "            .replace('*****', np.nan)\\\n",
    "            .replace('+', np.nan)\\\n",
    "            .replace('(X)', np.nan)\\\n",
    "            .replace('N', np.nan)\\\n",
    "            .replace('2,500-',np.nan)\\\n",
    "            .astype('float') \n",
    "        \n",
    "    def checkRows(self):\n",
    "        \"\"\" Check for rows where the count of null values are greater than a specified number.\n",
    "\n",
    "        Input:\n",
    "            self.n = int, the threshold of null values\n",
    "        \n",
    "        Print:\n",
    "            Statement with count of rows before removing those above the threshold.\n",
    "            Statement with count of columns containing >n null values\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Before removing null values, the length of the dataset is {} rows\".format(len(self.df)))\n",
    "        cols = [col for col in self.df.columns]\n",
    "        rowNone = self.df.isnull().sum(axis=1)\n",
    "        for index, value in rowNone.items():\n",
    "            if value >= self.n:\n",
    "                self.noneListR.append(index)\n",
    "        print('The {0} rows with >{1} null are: {2}'.format(len(self.noneListR), self.n, self.noneListR))\n",
    "        self.removeNullRows()\n",
    "        \n",
    "    def checkCols(self, remove=False):\n",
    "        \"\"\" Check for columns where Null values are greater than a specified number.\n",
    "        \n",
    "        Input: \n",
    "            self.n = int, the threshold of null values\n",
    "        \n",
    "        Print:\n",
    "            Statement with count of columns containing >n null values. \n",
    "        \"\"\"\n",
    "        \n",
    "        colNone = self.df.isnull().sum(axis=0)\n",
    "        for index, value in colNone.items():\n",
    "            if value >= self.n:\n",
    "                self.noneListC.append(index)\n",
    "        print('The remaining {0} columns with >{1} null are: {2}'\\\n",
    "              .format(len(self.noneListC), self.n, self.noneListC))\n",
    "                                 \n",
    "    def removeNullRows(self):\n",
    "        \"\"\"Removes the rows where nulls are greater than a specified number. Print new length of dataset.\"\"\"\n",
    "        noneList_shifted = list(np.array(self.noneListR) - np.array([1 for i in range(len(self.noneListR))])) #sebowman\n",
    "        xList = self.df.iloc[noneList_shifted, : ]\n",
    "        self.df = self.df.drop(self.df.index[[noneList_shifted]], axis = 0).reset_index(drop = True)\n",
    "        print(\"The length of the dataset is now {} rows\".format(len(self.df)))\n",
    "        \n",
    "        \n",
    "    # Customization methods   \n",
    "    \n",
    "    def readIn(self):\n",
    "        \"\"\" Obtain the pathname of the input csv file and check whether it is a valid pathname. \n",
    "        \n",
    "        Exception raised: FileNotFoundError: \n",
    "        if FileNotFoundError, repeat method.\n",
    "        If user entered an invalid pathname to the csv file, prompt for input again.\n",
    "        \n",
    "        Input:\n",
    "            inFile: str - input('Enter file name or pathname, including \".csv\": ').\n",
    "            Cannot be currently passed from main. \n",
    "        \n",
    "        Print:\n",
    "            Confirmation of pathname entered.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.inFile = input('Enter file name or pathname, including \".csv\": ')\n",
    "        print('Pathname entered: {}'.format(self.inFile))\n",
    "        try:\n",
    "            pd.read_csv(self.inFile)\n",
    "        except FileNotFoundError:\n",
    "            print('The file {} was not found. Please enter valid csv pathname.'.format(self.inFile))\n",
    "            self.readIn()  \n",
    "\n",
    "    def addCounty(self):\n",
    "        \"\"\" If the input is not None, add a column containing the county of each row.\n",
    "        \n",
    "        Input: \n",
    "            add: bool, default False. If passed from main as False, will be prompted for user input. \n",
    "            Press return for False (provide no input).\n",
    "        \n",
    "        Print: \n",
    "            Confirmation of choice- 'County column added: True/False'\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.add == False: \n",
    "            self.add = bool(input('Add county column? Enter any character for True. Else press return.'))\n",
    "        if self.add == True:\n",
    "            geography = self.df.loc[ : , 'Geography']\n",
    "            county_list = []\n",
    "            for entry in geography: \n",
    "                county_list.append(entry.split(',')[-2])\n",
    "            counties = np.array(county_list)\n",
    "            self.df['County'] = counties\n",
    "        print('County column added: {}'.format(self.add))\n",
    "        \n",
    "    def describe(self):\n",
    "        \"\"\" Prompt for whether user wants descriptive file made.\n",
    "        \n",
    "        If desc is False, prompt for input.\n",
    "        If no input to prompt, desc remains False. \n",
    "        If True, prompt for the filename, write to file. \n",
    "        \n",
    "        Input:\n",
    "            desc: bool, default False. If passed from main as False, will be prompted for user input\n",
    "            desc_file: str\n",
    "        \n",
    "        Print:\n",
    "            Confirmation of choice: 'Generate descriptive file: True/False'\n",
    "            Confirmation of pathname entered: 'Look in directory for the descriptive file [desc_file]'\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"if desc == False:\n",
    "            desc = bool(input('Generate descriptive file? Enter any character for True. Else press return.'))\n",
    "        print('Generate descriptive file: {}'.format(self.desc))\n",
    "        if desc == True:\n",
    "            desc_file = input('Enter descriptive file name or pathname, including \".csv\": ')\n",
    "            self.df.describe(include='all').to_csv(desc_file)\n",
    "            print('Look in directory for the descriptive file {}'.format(desc_file))\"\"\" \n",
    "            \n",
    "        desc = bool(input('Generate descriptive file? Enter any character for True. Else press return.'))\n",
    "        print('Generate descriptive file: {}'.format(desc))\n",
    "        if desc == True:\n",
    "            desc_file = input('Enter descriptive file name or pathname, including \".csv\": ')\n",
    "            if desc_file == '':\n",
    "                desc_file = None\n",
    "                self.describe()\n",
    "            self.df.describe(include='all').to_csv(desc_file)\n",
    "            print('Look in directory for the descriptive file {}'.format(desc_file))   \n",
    "            \n",
    "            \n",
    "    def whatOut(self):\n",
    "        \"\"\" Require user to enter a filename for the output if it was not given during initialization. \n",
    "        \n",
    "        If still None, prompt for input again.\n",
    "        \n",
    "        Input: \n",
    "            out: str, default None - input('Enter output file name or pathname, including \".csv\": ') or passed from main()\n",
    "        \"\"\"\n",
    "        \n",
    "        self.out = input('Enter output file name or pathname, including \".csv\": ')\n",
    "        if self.out == (None or ''):\n",
    "            self.whatOut()\n",
    "        \n",
    "                 \n",
    "                \n",
    "    # Header modification methods\n",
    "    def headers(self): \n",
    "        \"\"\" Rename the first two columns as 'id' and 'Geography' respectively, provide option to rename other headers.\n",
    "        \n",
    "        Rename 'GEO.id2' as 'id', 'GEO.display-label' as 'Geography'.\n",
    "        If niceName is not instantiated as True, prompt user as to whether to change the headers.\n",
    "        Depending on data, will change to those in povHeaders, eduHeaders or pluHeaders.\n",
    "        \n",
    "        Input: \n",
    "            niceName: bool, default False - \n",
    "            input('Prefer different headers? Enter any character for True. Else press return.') or passed from main()\n",
    "        \n",
    "        Print: \n",
    "            Confirmation of choice: True or False.\n",
    "        \"\"\"\n",
    "        \n",
    "        headers={'GEO.id2':'id',\n",
    "                 'GEO.display-label':'Geography'}\n",
    "        self.df.rename(columns=headers, inplace=True)\n",
    "        if self.niceName == False:\n",
    "            self.niceName = bool(input('Prefer different headers? Enter any character for True. Else press return.'))\n",
    "        print('Different headers is {}'.format(self.niceName))        \n",
    "\n",
    "    def povHeaders(self):\n",
    "        \"\"\"Change some of the headers of the plumbing dataset. Called if niceName == True.\n",
    "        \n",
    "        Include only headers with the code HC03 (percent poverty, percent poverty margin of error). \n",
    "        \"\"\"\n",
    "        \n",
    "        headers = {\n",
    "        'HC03_EST_VC01':'PPOV',\n",
    "        'HC03_MOE_VC01':'PPOV_MOE',\n",
    "        'HC03_EST_VC03':'PPOV_U18',\n",
    "        'HC03_MOE_VC03':'PPOV_U18_MOE',\n",
    "        'HC03_EST_VC04':'PPOV_U5',\n",
    "        'HC03_MOE_VC04':'PPOV_U5_MOE',\n",
    "        'HC03_EST_VC07':'PPOV_Adult_U64',\n",
    "        'HC03_MOE_VC07':'PPOV_Adult_U64_MOE',\n",
    "        'HC03_EST_VC10':'PPOV_Adult_60',\n",
    "        'HC03_MOE_VC10':'PPOV_Adult_60_MOE',\n",
    "        'HC03_EST_VC11':'PPOV_Adult_65',\n",
    "        'HC03_MOE_VC11':'PPOV_Adult_65_MOE',\n",
    "        'HC03_EST_VC14':'PPOV_Male',\n",
    "        'HC03_MOE_VC14':'PPOV_Male_MOE',\n",
    "        'HC03_EST_VC15':'PPOV_Female',\n",
    "        'HC03_MOE_VC15':'PPOV_Female_MOE',\n",
    "        'HC03_EST_VC72':'PPOV_Adult_65_74',\n",
    "        'HC03_MOE_VC72':'PPOV_Adult_65_74_MOE',\n",
    "        'HC03_EST_VC73':'PPOV_Adult_75',\n",
    "        'HC03_MOE_VC73':'PPOV_Adult_75_MOE'\n",
    "        }\n",
    "        self.df.rename(columns=headers, inplace=True)\n",
    "\n",
    "        \n",
    "    def eduHeaders(self):\n",
    "        \"\"\" Currently no change of the headers in the education dataset. Called if niceName == True.\"\"\"\n",
    "        \n",
    "        print('Education does not currently have alternative headers')\n",
    "\n",
    "        \n",
    "    def pluHeaders(self):\n",
    "        \"\"\" Change the headers of the plumbing dataset. Called if niceName == True.\"\"\"\n",
    "        \n",
    "        headers = {\n",
    "        'HD01_VD01':'PLU_Total',\n",
    "        'HD02_VD01':'PLU_Total_MOE',\n",
    "        'HD01_VD02':'PLU_Complete',\n",
    "        'HD02_VD02':'PLU_Complete_MOE',\n",
    "        'HD01_VD03':'PLU_Lacking',\n",
    "        'HD02_VD03':'PLU_Lacking_MOE',\n",
    "        }\n",
    "        self.df.rename(columns=headers, inplace=True)\n",
    "\n",
    "        \n",
    "\n",
    "def main():\n",
    "    \"\"\" Instantiate ACSdata. All parameters can be given during execution as text input.\n",
    "    \n",
    "    Assumes data is in the same format as ACS 5-year estimate data for poverty, education or plumbing.   \n",
    "    Currently requires text inputs from the user for parameters other than booleans. \n",
    "    \n",
    "    Optional parameters, with their default values, descriptions:\n",
    "        niceName=False, change headers?\n",
    "        add=False, add County column?\n",
    "        drop=True, drop the education data columns that are not involved in current analyses this code was made for. \n",
    "        \n",
    "\n",
    "    For niceName, add, desc: unless set to True during instantiation, user will be prompted again.  \n",
    "    \"\"\"\n",
    "\n",
    "    file = ACSdata()\n",
    "    file.newFile()\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
